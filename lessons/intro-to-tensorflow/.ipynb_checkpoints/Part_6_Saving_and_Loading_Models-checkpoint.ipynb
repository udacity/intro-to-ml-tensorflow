{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7sePAkWpLJV"
   },
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, we'll see how to save and load models with TensorFlow. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tD856SqhH4JK"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hsu5egUUqPg9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BqsrWYDKp4Fd",
    "outputId": "5fe90392-c56f-423f-bc89-b9fc985feecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.0.0-beta1\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• GPU device not found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAe81nXoICzC"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "bxcg_ZbuLnM3",
    "outputId": "33841a52-53e6-4e8a-ecbd-b448bf3c46f5"
   },
   "outputs": [],
   "source": [
    "train_split = 60\n",
    "test_val_split = 20\n",
    "\n",
    "splits = tfds.Split.ALL.subsplit([train_split, test_val_split, test_val_split])\n",
    "\n",
    "dataset, dataset_info = tfds.load('fashion_mnist', split=splits, as_supervised=True, with_info=True)\n",
    "\n",
    "training_set, validation_set, test_set = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1WhOLC7Ii3D"
   },
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9i2586KjI4QM",
    "outputId": "24ccc17a-c3f6-44ba-edc3-ae267e628fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42,000 images in the training set\n",
      "There are 14,000 images in the validation set\n",
      "There are 14,000 images in the test set\n"
     ]
    }
   ],
   "source": [
    "total_examples = dataset_info.splits['train'].num_examples + dataset_info.splits['test'].num_examples\n",
    "\n",
    "num_training_examples = (total_examples * train_split) // 100\n",
    "num_validation_examples = (total_examples * test_val_split) // 100\n",
    "num_test_examples = num_validation_examples\n",
    "\n",
    "print('There are {:,} images in the training set'.format(num_training_examples))\n",
    "print('There are {:,} images in the validation set'.format(num_validation_examples))\n",
    "print('There are {:,} images in the test set'.format(num_test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLMJCpppq43U"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "PeU9nb_xqW98",
    "outputId": "7e35ce36-2589-4b3e-b2bf-313eaa2414f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f406552e048>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 305
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.title(class_names[label])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5rUDqxBIt5N"
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec3uphcyci3c"
   },
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_batches = training_set.cache().shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
    "validation_batches = validation_set.cache().batch(batch_size).map(normalize).prefetch(1)\n",
    "testing_batches = test_set.cache().batch(batch_size).map(normalize).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySQuJ-iPqNoR"
   },
   "source": [
    "## Build and Train the Model\n",
    "\n",
    "Here we'll build and compile our model as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "47Vnu0KJMqwc",
    "outputId": "f1abd9d1-db9e-4bfd-99c7-d4376adb8745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_neurons = [512, 256, 128]\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28,1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1qLJ-cAwnmFD",
    "outputId": "32be0a8a-5cfb-473f-872c-e09da279eae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "657/657 [==============================] - 30s 45ms/step - loss: 0.8426 - accuracy: 0.6932 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/4\n",
      "657/657 [==============================] - 27s 41ms/step - loss: 0.5706 - accuracy: 0.7977 - val_loss: 0.4371 - val_accuracy: 0.8412\n",
      "Epoch 3/4\n",
      "657/657 [==============================] - 27s 41ms/step - loss: 0.5117 - accuracy: 0.8184 - val_loss: 0.4168 - val_accuracy: 0.8483\n",
      "Epoch 4/4\n",
      "657/657 [==============================] - 27s 42ms/step - loss: 0.4896 - accuracy: 0.8269 - val_loss: 0.4140 - val_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "history = model.fit(training_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jseIvfe2xb56"
   },
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "In TensorFlow we can save our trained models in different formats. Here we will see how to save our models in TensorFlow's SavedModel format and as HDF5 files, which is the format used by Keras models.\n",
    "\n",
    "### Saving and Loading Models in HDF5 Format\n",
    "\n",
    "To save our models in the format used by Keras models we use the `.save(filepath)` method. For example, to save a model called `my_model` in the current working directory with the name `test_model` we use:\n",
    "\n",
    "```python\n",
    "my_model.save('./test_model.h5')\n",
    "```\n",
    "\n",
    "It's important to note that we have to provide the `.h5` extension to the `filepath` in order the tell `tf.keras` to save our model as an HDF5 file. \n",
    "\n",
    "The above command saves our model into a single HDF5 file that will contain:\n",
    "\n",
    "* The model's architecture.\n",
    "* The model's weight values which were learned during training.\n",
    "* The model's training configuration, which corresponds to the parameters you passed to the `compile` method.\n",
    "* The optimizer and its state. This allows you to resume training exactly where you left off.\n",
    "\n",
    "\n",
    "In the cell below we save our trained `model` as an HDF5 file. The name of our HDF5 will correspond to the current time stamp. This is useful if you are saving many models and want each of them to have a unique name. By default the `.save()` method will **silently** overwrite any existing file at the target location with the same name. If we want `tf.keras` to provide us with a manual prompt to whether overwrite files with the same name, you can set the argument `overwrite=False` in the `.save()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1dOvNRvrhNa"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "saved_keras_model_filepath = './{}.h5'.format(int(t))\n",
    "\n",
    "model.save(saved_keras_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGNRBb1puSRg"
   },
   "source": [
    "Once a model has been saved, we can use `tf.keras.models.load_model(filepath)` to re-load our model. This command will also compile our model automatically using the saved training configuration, unless the model was never compiled in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "akaAVE2js5d0",
    "outputId": "84301998-a6c3-4a55-c5f1-f76d086290bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reloaded_keras_model = tf.keras.models.load_model(saved_keras_model_filepath)\n",
    "\n",
    "reloaded_keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWihP1oMjNeF"
   },
   "source": [
    "As we can see the re-loaded model has the same architecture as our original model, as it should be. At this point, since we haven't done anything new to the re-loaded model, then both the `reloaded_keras_model` our original `model` should be identical copies. Therefore, they should make the same predictions on the same images. Let's check that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gLQsw7QVkElc",
    "outputId": "0d00e16b-9fdd-4d34-b9ab-96956ddbf5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    prediction_1 = model.predict(image_batch)\n",
    "    prediction_2 = reloaded_keras_model.predict(image_batch)\n",
    "    difference = np.abs(prediction_1 - prediction_2)\n",
    "    print(difference.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-dDOY0BmYhs"
   },
   "source": [
    "As we can see, the result is 0.0, which indicates that both models made the same predictions on the same images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxHdz18pQUNV"
   },
   "source": [
    "### Saving and Loading TensorFlow SavedModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGtK83g2vVki"
   },
   "source": [
    "To export our models to the TensorFlow **SavedModel** format, we use the `tf.saved_model.save(model, export_dir)` function. For example, to save a model called `my_model` in a folder called `saved_models` located in the current working directory we use:\n",
    "\n",
    "```python\n",
    "tf.saved_model.save(my_model, './saved_models')\n",
    "```\n",
    "\n",
    "It's important to note that here we have to provide the path to the directory where we want to save our model, **NOT** the name of the file. This is because SavedModels are not saved in a single file. Rather, when you save your model as a SavedModel, `the tf.saved_model.save()` function will create an `assets` folder, a `variables` folder, and a `saved_model.pb` file inside the directory you provided.\n",
    "\n",
    "The SavedModel files that are created contain:\n",
    "\n",
    "* A TensorFlow checkpoint containing the model weights.\n",
    "* A SavedModel proto containing the underlying TensorFlow graph. Separate graphs are saved for prediction (serving), training, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "* The model's architecture configuration if available.\n",
    "\n",
    "The SavedModel is a standalone serialization format for TensorFlow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. It does not require the original model building code to run, which makes it useful for sharing or deploying in different platforms, such as mobile and embedded devices (with TensorFlow Lite), servers (with TensorFlow Serving), and even web browsers (with TensorFlow.js).\n",
    "\n",
    "In the cell below we save our trained model as a SavedModel. The name of the folder where we are going to save our model will correspond to the current time stamp. Again, this is useful if you are saving many models and want each of them to be saved in a unique directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "V2C0F3luxzlI",
    "outputId": "80a362e5-008f-4f54-ffb5-0b5577b5c46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40642202f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40642202f0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f405150f378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f405150f378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649f6378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649f6378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f405150f488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f405150f488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649dfc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649dfc80>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f405150f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f405150f268>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406494d730> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406494d730>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f405150f598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f405150f598>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406496c7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406496c7b8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24950>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406496cea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406496cea0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24950>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24a60>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406492d6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406492d6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24a60>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24c80>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648f92f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648f92f0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a24d90>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648b9158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648b9158>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24598>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648b9d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40648b9d90>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f4064a24598>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a246a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a246a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064865b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064865b70>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a246a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f4064a246a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3048>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064832378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064832378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647f5488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647f5488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647f5d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647f5d08>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c3378>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406479de18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f406479de18>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c3488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c36a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c36a8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064777ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064777ea0>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c37b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649c37b8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064725268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4064725268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649f66a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40649f66a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649f6510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649f6510>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647250d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40647250d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _extract_outputs_from_fn.<locals>.call at 0x7f40649f6510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _extract_outputs_from_fn.<locals>.call at 0x7f40649f6510>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7f40649c39d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f40649c38c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f40649c38c8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40645d57b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f40645d57b8>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "savedModel_directory = './{}'.format(int(t))\n",
    "\n",
    "tf.saved_model.save(model, savedModel_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBY1j0QEyjPi"
   },
   "source": [
    "Once a model has been saved as a SavedModel, we can use `tf.saved_model.load(export_dir)` to re-load our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRx2y2M4AtKl"
   },
   "outputs": [],
   "source": [
    "reloaded_SavedModel = tf.saved_model.load(savedModel_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJwmzT1gAwew"
   },
   "source": [
    "It's important to note that the object returned by `tf.saved_model.load` is **NOT** a Keras object. Therefore, it doesn't have `.fit`, `.predict`, `.summary`, etc. methods. It is 100% independent of the code that created it. This means that in order to make predictions with our `reloaded_SavedModel` we need to use a different method than the one used with the re-loaded Keras model.\n",
    "\n",
    "To make predictions on a batch of images with a re-loaded SavedModel we have to use:\n",
    "\n",
    "```python\n",
    "reloaded_SavedModel(image_batch, training=False)\n",
    "```\n",
    "\n",
    "This will return a tensor with the predicted label probabilities for each image in the batch. Again, since we haven't done anything new to this re-loaded SavedModel, then both the `reloaded_SavedModel` and our original `model` should be identical copies. Therefore, they should make the same predictions on the same images. Let's check that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ozMqD1ZoER5g",
    "outputId": "17769afa-1a1f-48c4-80e5-a389c80f4062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7881393e-07\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    prediction_1 = model.predict(image_batch)\n",
    "    prediction_2 = reloaded_SavedModel(image_batch, training=False).numpy()\n",
    "    difference = np.abs(prediction_1 - prediction_2)\n",
    "    print(difference.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QZNNPkYFH3D"
   },
   "source": [
    "We can also get back a full Keras model, from a TensorFlow SavedModel, by loading our SavedModel with the `tf.keras.models.load_model` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0BxFJcGLyMTD",
    "outputId": "a2fefa76-57b5-4a9e-8c05-b8a1ae7f31a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Flatten object at 0x7f405d692cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Flatten object at 0x7f405d692cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d692908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d692908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d6977b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d6977b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f407555ccf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f407555ccf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f405d697da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d69e160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method RevivedLayer.call of <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f405d69e160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reloaded_keras_model_from_SavedModel = tf.keras.models.load_model(savedModel_directory)\n",
    "\n",
    "reloaded_keras_model_from_SavedModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FomAlrxnQnm8"
   },
   "source": [
    "## Saving Models During Training\n",
    "\n",
    "We have seen that when we train a model with a validation set, the value of the validation loss changes through the training process. Since the value of the validation loss is an indicator of how well our model will generalize to new data, it will be great if could save our model at each step of the training process and then only keep the version with the lowest validation loss. \n",
    "\n",
    "We can do this in `tf.keras` by using the following callback:\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.ModelCheckpoint('./best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "```\n",
    "This callback will save the model as a Keras HDF5 file after every epoch. With the `save_best_only=True` argument, this callback will first check the validation loss of the latest model against the one previously saved. The callback will only save the latest model and overwrite the old one, if the latest model has a lower validation loss than the one previously saved. This will guarantee that will end up with the version of the model that achieved the lowest validation loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "vvsuAeUQ1WKR",
    "outputId": "b8ee7834-f46e-4141-d61c-83cd7d72a333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 26s 39ms/step - loss: 0.5392 - accuracy: 0.8062 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 23s 36ms/step - loss: 0.3876 - accuracy: 0.8574 - val_loss: 0.3753 - val_accuracy: 0.8634\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.3479 - accuracy: 0.8715 - val_loss: 0.3563 - val_accuracy: 0.8699\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.3190 - accuracy: 0.8815 - val_loss: 0.3558 - val_accuracy: 0.8718\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2971 - accuracy: 0.8883 - val_loss: 0.3659 - val_accuracy: 0.8682\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2800 - accuracy: 0.8947 - val_loss: 0.3539 - val_accuracy: 0.8749\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2670 - accuracy: 0.8994 - val_loss: 0.3608 - val_accuracy: 0.8766\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 23s 36ms/step - loss: 0.2547 - accuracy: 0.9031 - val_loss: 0.3575 - val_accuracy: 0.8776\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2403 - accuracy: 0.9083 - val_loss: 0.3736 - val_accuracy: 0.8749\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2335 - accuracy: 0.9105 - val_loss: 0.3686 - val_accuracy: 0.8781\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2215 - accuracy: 0.9147 - val_loss: 0.3789 - val_accuracy: 0.8774\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2131 - accuracy: 0.9204 - val_loss: 0.3524 - val_accuracy: 0.8820\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.2018 - accuracy: 0.9244 - val_loss: 0.3825 - val_accuracy: 0.8779\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1971 - accuracy: 0.9241 - val_loss: 0.3702 - val_accuracy: 0.8805\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 23s 36ms/step - loss: 0.1890 - accuracy: 0.9278 - val_loss: 0.3832 - val_accuracy: 0.8773\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1829 - accuracy: 0.9308 - val_loss: 0.3961 - val_accuracy: 0.8756\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 23s 36ms/step - loss: 0.1775 - accuracy: 0.9326 - val_loss: 0.3965 - val_accuracy: 0.8717\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1692 - accuracy: 0.9364 - val_loss: 0.3926 - val_accuracy: 0.8825\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 23s 36ms/step - loss: 0.1617 - accuracy: 0.9384 - val_loss: 0.3952 - val_accuracy: 0.8828\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1625 - accuracy: 0.9383 - val_loss: 0.4189 - val_accuracy: 0.8757\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: 0.4226 - val_accuracy: 0.8689\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 23s 35ms/step - loss: 0.1533 - accuracy: 0.9417 - val_loss: 0.4154 - val_accuracy: 0.8769\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 10 consecutive epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Save the Model with the lowest validation loss\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint('./best_model.h5',\n",
    "                                               monitor='val_loss',\n",
    "                                               save_best_only=True)\n",
    "\n",
    "history = model.fit(training_batches,\n",
    "                    epochs = 100,\n",
    "                    validation_data=validation_batches,\n",
    "                    callbacks=[early_stopping, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz4snGQsR2Mg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 6 - Saving and Loading Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
